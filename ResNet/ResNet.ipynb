{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faaca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e61004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load CSV Files\n",
    "train_df = pd.read_csv('cardatasettrain.csv')\n",
    "test_df = pd.read_csv('cardatasettest.csv')\n",
    "\n",
    "# Clean DataFrames\n",
    "train_df_clean = train_df.drop(columns=['Unnamed: 0'])\n",
    "test_df_clean = test_df.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7781e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define image loading function with consistent shape handling\n",
    "def load_images(dataframe, folder_path, img_size=(64, 64)):\n",
    "    images = []\n",
    "    for img_name in dataframe['image']:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path).resize(img_size).convert('RGB')  # Ensure RGB\n",
    "            img_array = np.array(img).flatten()  # Flatten the image\n",
    "            images.append(img_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_name}: {e}\")\n",
    "            continue\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# Load training and testing images\n",
    "train_images = load_images(train_df_clean, \"cars_train/cars_train\")\n",
    "test_images = load_images(test_df_clean, \"cars_test/cars_test\")\n",
    "\n",
    "# Verify loaded image shapes\n",
    "print(f\"Train Images Shape: {train_images.shape}\")\n",
    "print(f\"Test Images Shape: {test_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract bounding box features\n",
    "train_boxes = train_df_clean[['x1', 'y1', 'x2', 'y2']].values\n",
    "test_boxes = test_df_clean[['x1', 'y1', 'x2', 'y2']].values\n",
    "\n",
    "# Combine image features with bounding boxes\n",
    "X_train_full = np.hstack((train_boxes, train_images))\n",
    "X_test = np.hstack((test_boxes, test_images))\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(train_df_clean['Class'].values)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_encoded, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define ResNet-based model\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=196):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29619cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, criterion, optimizer, and data loaders\n",
    "model = ResNetModel(num_classes=196).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    val_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    val_acc = val_corrects / len(val_loader.dataset)\n",
    "    print(f'Validation Acc: {val_acc:.4f}')\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_resnet_model.pth')\n",
    "print(f'Best Validation Accuracy: {best_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the trained model\n",
    "model.eval()\n",
    "y_train_pred = []\n",
    "y_val_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, 1).cpu().numpy()\n",
    "        y_train_pred.extend(preds)\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, 1).cpu().numpy()\n",
    "        y_val_pred.extend(preds)\n",
    "\n",
    "# Calculate metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "print(f'Validation F1 Score: {val_f1:.2f}')\n",
    "print(f'Validation Precision: {val_precision:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d92eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_filename = \"fastai_resnet.pkl\"\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model.state_dict(), file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c0149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
